{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-550caa57204a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2226\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mpylab\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mpylab\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mimport_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_import_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclobbered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pylab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Populating the interactive namespace from numpy and matplotlib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_pylab\u001b[0;34m(self, gui, import_all, welcome_message)\u001b[0m\n\u001b[1;32m   3138\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylabtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_pylab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;31m# We want to prevent the loading of pylab to pollute the user's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \"\"\"\n\u001b[1;32m   3088\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3089\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/william/miniconda/envs/cenv/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-free grammar text generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Clean and tag a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import glob\n",
    "import random\n",
    "# import cPickle as pickle\n",
    "import pickle\n",
    "  \n",
    "path = 'revelation/revelation.txt'   \n",
    "corpus_members=glob.glob(path)\n",
    "corpus = ''\n",
    "# get rid of random line breaks and exclude troublesome expressions like quotes\n",
    "for member in corpus_members:\n",
    "    with open (member, \"r\") as openfile:\n",
    "        data = openfile.read()\n",
    "        for badchar in ['\\t','\\n','-\\n','\\'','\\\"','`','|','--']:\n",
    "            data = data.replace(badchar, ' ')\n",
    "        data = data.replace('.','. ')\n",
    "        data = data.replace(',',', ')\n",
    "        data = data.replace(';','; ')\n",
    "        data = data.replace(':',': ')\n",
    "    corpus = corpus + ' '+ data\n",
    "tokens = nltk.word_tokenize(corpus)\n",
    "\n",
    "# looks at each word in the context of sentence and tags it\n",
    "pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "pickle.dump( pos_tagged_tokens, open( \"revelation/revelation_tagged.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record all terminal characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('revelation/revelation_tagged.pkl', 'rb') as handle:\n",
    "    pos_tagged_tokens = pickle.load(handle)\n",
    "\n",
    "# clear file\n",
    "open('revelation/revelation_rules.txt', 'w').close()\n",
    "\n",
    "file = open('revelation/revelation_rules.txt', 'a')\n",
    "\n",
    "# need to come up with some valid rules\n",
    "# tree = '''S -> NP VP\n",
    "# PP -> IN NP\n",
    "# NP -> DT NN | DT NN PP\n",
    "# VP -> VB NP | VP PP \\n'''\n",
    "# file.write(tree)\n",
    "\n",
    "tags = list({tupe[1] for tupe in pos_tagged_tokens})\n",
    "# dollar signs make everything go wrong\n",
    "#tags = [item.replace('$','x')for item in tags]\n",
    "badtags = ['#','$',',','-NONE-','.',':','TO','POS',\"''\"] # try to get NONE back if possible\n",
    "tags = [item for item in tags if item not in badtags]\n",
    "for tag in tags:\n",
    "#     if tag in ['#','$',',','-NONE-','.',':']:\n",
    "#         continue\n",
    "#     else:\n",
    "    allsyms = [('\\'' + tupe[0] + '\\'') for tupe in pos_tagged_tokens if tupe[1]== tag]\n",
    "    gr_rule = (tag + \" -> \")\n",
    "    gr_rule += ' | '.join(allsyms)\n",
    "    gr_rule += '\\n'\n",
    "    gr_rule = gr_rule.replace('PRP$','PRPx')\n",
    "    gr_rule = gr_rule.replace('WP$','WPx')\n",
    "    gr_rule = gr_rule.replace('-NONE-','xNONEx')\n",
    "    file.write(gr_rule)\n",
    "\n",
    "# specify these guys when creating grammar\n",
    "# still need to work with apostrophe, hypens ``\n",
    "file.write('''xperiod -> '.'\\n''')\n",
    "file.write('''xcomma -> ','\\n''')\n",
    "file.write('''xcolon -> ':'\\n''')\n",
    "file.write('''xsemicolon -> ';'\\n''')\n",
    "file.write('''openparen -> '('\\n''')\n",
    "file.write('''closeparen -> ')'\\n''')\n",
    "file.write('''xapostrophe -> \"\\'\"\\n''')\n",
    "file.write('''xquote -> \"''\"\\n''')\n",
    "\n",
    "# Save some compiling time\n",
    "file.write('''TO -> 'to'\\n''')\n",
    "\n",
    "# need to fix this\n",
    "#file.write('''POS -> \"\\'s\"\\n''')\n",
    "\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get Random sentence from corpus and print syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Grammar Model\n",
      "Time: (6.78)s\n",
      "\n",
      "And there they shall be tortured day and night for timeless  ages.\n",
      "NPxSBARxS -> S S\n",
      "S -> CC NP NP VP\n",
      "CC -> 'and'\n",
      "NP -> EX\n",
      "EX -> 'there'\n",
      "NP -> PRP\n",
      "PRP -> 'they'\n",
      "VP -> MD VB NP\n",
      "MD -> 'shall'\n",
      "VB -> 'be'\n",
      "NP -> JJ NN\n",
      "JJ -> 'tortured'\n",
      "NN -> 'day'\n",
      "S -> CC VP xperiod\n",
      "CC -> 'and'\n",
      "VP -> NP PP\n",
      "NP -> NN\n",
      "NN -> 'night'\n",
      "PP -> IN NP\n",
      "IN -> 'for'\n",
      "NP -> JJ NN\n",
      "JJ -> 'timeless'\n",
      "NN -> 'ages'\n",
      "xperiod -> 'xperiod'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "from random import choice\n",
    "\n",
    "from stat_parser import Parser\n",
    "parser = Parser()\n",
    "# pick a random sentence to parse\n",
    "# leave out the period at the end of the sentence\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "rsent = choice(tokenizer.tokenize(corpus))\n",
    "print (rsent)\n",
    "parsee=parser.parse(rsent)\n",
    "\n",
    "rules = \"\"\n",
    "to_replace = [',','.',':',';',\"''\",'(',')','$','+']\n",
    "replacements = ['xcomma','xperiod','xcolon','xsemicolon',\\\n",
    "                'xquote','openparen','closeparen','x','x']\n",
    " \n",
    "# possibly add: brackets, double quotes\n",
    "\n",
    "for production in parsee.productions():\n",
    "    rules += str(production) + '\\n'\n",
    "\n",
    "# now re-tag special characters\n",
    "swappairs = zip(to_replace, replacements)\n",
    "for member in swappairs:\n",
    "    rules = rules.replace(member[0],member[1])\n",
    "\n",
    "print (rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grammar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gramr = nltk.parse_cfg(\"\"\"S -> NP VP\n",
    "# ... PP -> P NP\n",
    "# ... NP -> Det N | Det N PP | 'I'\n",
    "# ... VP -> V NP | VP PP\n",
    "# ... Det -> 'an' | 'my'\n",
    "# ... N -> 'elephant' | 'pajamas'\n",
    "# ... V -> 'shot'\n",
    "# ... P -> 'in'\n",
    "# ... \"\"\")\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk import CFG, ChartParser, Nonterminal\n",
    "from random import choice\n",
    "\n",
    "def is_terminal(item):\n",
    "    \"\"\"\n",
    "    Check to see if a symbol is terminal\n",
    "    \"\"\"\n",
    "    return hasattr(item, '__hash__') and not isinstance(item, Nonterminal)\n",
    "\n",
    "def produce(grammar, symbol):\n",
    "    words = []\n",
    "    productions = grammar.productions(lhs = symbol)\n",
    "    production = choice(productions)\n",
    "    for sym in production.rhs():\n",
    "        if is_terminal(sym):\n",
    "            words.append(sym)\n",
    "        # recursion\n",
    "        else:\n",
    "            words.extend(produce(grammar, sym))\n",
    "    return words\n",
    "\n",
    "# read nonterminal rules from treebank file\n",
    "file = open('revelation/revelation_NTrules.txt', 'r')\n",
    "cfg_str = file.read()\n",
    "file.close()\n",
    "\n",
    "# read leaves from corpus\n",
    "file = open('revelation/revelation_rules.txt', 'r')\n",
    "cfg_str += '\\n' + file.read()\n",
    "file.close()\n",
    "\n",
    "grammar = CFG.fromstring('''\n",
    "S -> NP',' VP\n",
    "PP -> IN NP\n",
    "NP -> DT NN | DT NN PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "V -> 'shot' | 'killed' | 'wounded'\n",
    "DT -> 'an' | 'my'\n",
    "NN -> 'elephant'\n",
    "H -> 'unused'\n",
    "IN -> 'in' | 'outside'\n",
    "''')\n",
    "\n",
    "grammar = CFG.fromstring(cfg_str)\n",
    "\n",
    "parser = ChartParser(grammar)\n",
    "\n",
    "gr = parser.grammar()\n",
    "\n",
    "# make an S symbol to start the fun\n",
    "tgr = ChartParser(CFG.fromstring('''S -> NP VP''')).grammar()\n",
    "tgr.start()\n",
    "# gr.max_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", dominates to purified up of These shone at , her credit at his blood and can twelve endurance of its everlasting be their angel , .\n",
      "and even will your authority was not upon the heat upon me from his hand .\n",
      "great shone throughout those harvest hand his thousand\n",
      "and been of earth cloud .\n",
      "they with fall Jesus what the double shot which own earth of the as she to the west to the quart are saw The someone upon A fellow handing who hate in you and hand Who have were them are created her presence of the point to be her stone , the statue were silk a front what which have to HARLOTS of mighty what are of the one-third , and any 1 kings xcolon the reward , or to our noises whose judgments sit will John was be to you to herself to sky , and can drown a voice to the harvest on Lamb heard given their hand Around the thousand . and any great bronze which have with the nor the holding to it which are need worshiped no anyone the shall try the forth statue to , great forth statue who earth sixth over her statue whose thunders are poured furnace blind song foot to its power into nor harm the right . are found your golden which call with the sea for There to will the complete roar are poured Alas shall these earth none shut I from their man to Jesus on Face for angel\n",
      "hast whose inhabitants sharp earth to single jewels of your sunlight which descending another trumpet , from The will salve the sound\n",
      "a blew reign all seashore of I against spotless of there\n",
      "and back scorch , their words .\n",
      "And even come the myrrh .\n",
      "fellow lampstands be fire this new honor whose players have shall entice the thousand like him become of his torture for the mixing of great kings or my book Who is to are was THE bird The man was never to there\n"
     ]
    }
   ],
   "source": [
    "#message = produce(gr, tgr.start())\n",
    "for ii in xrange(10):\n",
    "    print ' '.join(produce(gr, tgr.start())) \n",
    "\n",
    "\n",
    "# # tokenize by sentence and pick some random sentences to use?\n",
    "# # really need to get punctuation working\n",
    "# from stat_parser import Parser\n",
    "# parser = Parser()\n",
    "# kk=parser.parse(\"At the end of the nineteenth century the well-tested mechanical principles of Isaac Newton were the very heart of physical theory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a grammar file from Treebank"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# problem: searching for only identifiable tags is dropping clause symbols, etc. \n",
    "# But if a terminal symbo is missing, an IndexError will be raised\n",
    "# instead just make an lhs list and check for membership?\n",
    "\n",
    "rule_list = ''\n",
    "gram_leaves = [loc.rhs() for loc in list(tbank_productions)]\n",
    "gram_heads = [loc.lhs() for loc in list(tbank_productions)]\n",
    "gram_list= list(tbank_productions)\n",
    "for thing in gram_list:\n",
    "    thing_head = thing.lhs()\n",
    "    thing_leave = thing.rhs()\n",
    "    if str(thing_head) in tags:\n",
    "        #print str(thing_head)\n",
    "        continue\n",
    "    else:\n",
    "        message = str(thing_head) + \" -> \"\n",
    "        collection = [str(thing2) for thing2 in thing_leave]\n",
    "        for item in collection:\n",
    "            message += \" | \" + str(item)\n",
    "            rule_list += '\\n'+message\n",
    "\n",
    "    \n",
    "# # Get rid of dead heads\n",
    "# new_rule_list= ''\n",
    "# for line in rule_list.splitlines():\n",
    "#     if ' -> ' not in line[-5:]:\n",
    "#         new_rule_list +=line+'\\n'\n",
    "        \n",
    "rule_list=new_rule_list\n",
    "\n",
    "#get ride of first OR\n",
    "rule_list = rule_list.replace(' ->  |', ' ->  ')\n",
    "\n",
    "print rule_list\n",
    "# file = open('treebank_rules.txt', 'w')\n",
    "# file.write(rule_list)\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = ChartParser(tbank_grammar)\n",
    "gr = parser.grammar()\n",
    "print ' '.join(produce(gr, gr.start()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
