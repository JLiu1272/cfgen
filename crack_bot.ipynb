{
 "metadata": {
  "name": "",
  "signature": "sha256:b0618b889277bea47b4127bef4b62f07c45615feb29c4ad9d45a3a7cd8197a67"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preamble"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "rcParams['font.family'] = 'DIN Pro'\n",
      "rcParams['font.weight'] = 'medium'\n",
      "# # These are the \"Tableau 20\" colors as RGB.  \n",
      "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
      "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
      "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
      "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
      "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
      "tableau20 = [(0.59375, 0.257813, 0.886719),(0.800781, 0.0625, 0.460938), (0.278431, 0.788235, 0.478431), (0.917647, 0.682353, 0.105882), (0.372549, 0.596078, 1.), (0.8, 0.8, .8), (1.0, .3882, .2784)];\n",
      "for i in range(len(tableau20)):  \n",
      "    r, g, b = tableau20[i]  \n",
      "    tableau20[i] = (r, g, b)\n",
      "    # tableau20[i] = (r / 255., g / 255., b / 255.)  \n",
      "\n",
      "bcolor = 'Grey'\n",
      "\n",
      "rcParams['axes.color_cycle'] = tableau20\n",
      "rcParams['axes.labelcolor'] = bcolor\n",
      "rcParams['axes.edgecolor'] = bcolor\n",
      "rcParams['xtick.color'] = bcolor\n",
      "rcParams['ytick.color'] = bcolor\n",
      "\n",
      "rcParams['legend.frameon'] = False\n",
      "\n",
      "rcParams['axes.facecolor'] = 'none'\n",
      "\n",
      "rcParams['lines.linewidth'] = 2\n",
      "\n",
      "rcParams['figure.facecolor'] = 'none'\n",
      "rcParams['savefig.facecolor'] = 'none'\n",
      "\n",
      "#rcParams['figure.savefig.bbox']= 'none'\n",
      "\n",
      "plot([1, 3, 2, 3],[1, 2, 4 ,6], [5, 1 ,3, 5],[6, 2, 5, 1])\n",
      "savefig(\"out.pdf\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/backends/backend_pdf.py:1007: UserWarning: 'DINPro-Medium.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
        "  os.path.basename(filename))\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAOABNGsAAB5AswYA4IH/BzK6NWk7k9QgAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x104d8e950>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Markov comment bot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import praw\n",
      "import string\n",
      "user_agent = (\"Data scraper 1.0 by /u/\")\n",
      "r = praw.Reddit(user_agent=user_agent)\n",
      "r.login('testbots','ertdfgCVB')\n",
      "\n",
      "# get a list of frequent subreddit users for the past six months\n",
      "srt_name = \"Physics\"\n",
      "srt = r.get_subreddit(srt_name)\n",
      "coms = srt.get_comments(limit=None)\n",
      "ct = 0;\n",
      "recent_names={};\n",
      "for comment in coms:\n",
      "    # don't get the deleted accounts since they're hard to work with\n",
      "    if comment.author is None:\n",
      "        continue\n",
      "    if comment.author.name in recent_names:\n",
      "        recent_names[comment.author.name] += 1\n",
      "    else:\n",
      "        recent_names[comment.author.name] = 1\n",
      "    ct += 1\n",
      "    if ct > 2000:\n",
      "        print \"stahp\"\n",
      "        break\n",
      "ords = sorted([(recent_names[x], x) for x in recent_names])\n",
      "all_top = ords[-25:]\n",
      "# A string list of the heaviest users\n",
      "top_users = [usr for (x, usr) in all_top]\n",
      "\n",
      "# fetch the top users in /r/physics\n",
      "topusrs = {}\n",
      "for usr in top_users:\n",
      "    topusrs[usr] = r.get_redditor(usr)\n",
      "\n",
      "# make an empty dict into which all their comments will be placed\n",
      "top_user_words = {}\n",
      "for usr in topusrs:\n",
      "    user = topusrs[usr]\n",
      "    ucom = user.get_submitted(limit=500)\n",
      "    comment_string = \"\"\n",
      "    for thing in ucom:\n",
      "        #flat_comments = praw.helpers.flatten_tree(thing.comments)\n",
      "        for comment in thing.comments:\n",
      "            comment_string = comment_string + \" \" + comment.body\n",
      "    # split string into words and assign\n",
      "    top_user_words[user.name] = comment_string.split()\n",
      "    break\n",
      "\n",
      "#\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# make an empty dict into which all the comments will be placed\n",
      "top_user_words = {}\n",
      "for usr in topusrs:\n",
      "    user = topusrs[usr]\n",
      "    ucom = user.get_submitted(limit=500)\n",
      "    comment_string = \"\"\n",
      "    for thing in ucom:\n",
      "        #flat_comments = praw.helpers.flatten_tree(thing.comments)\n",
      "        for comment in thing.comments:\n",
      "            comment_string = comment_string + \" \" + comment.body\n",
      "    # split string into words and assign\n",
      "    top_user_words[user.name] = comment_string.split()\n",
      "    break\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "#pick first from list\n",
      "kk = [topusrs[thing].name for thing in topusrs][0]\n",
      "\n",
      "bodytext = top_user_words[kk]\n",
      "seed_word = \"the\"\n",
      "message = seed_word\n",
      "while len(message) < 1000:\n",
      "    found_indices = [i for (i, x) in enumerate(bodytext) if x == seed_word]\n",
      "    next_words = [bodytext[index + 1] for index in found_indices]\n",
      "    next_word = random.choice(next_words)\n",
      "    message = message +' '+next_word\n",
      "    seed_word = next_word\n",
      "\n",
      "print message"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "un = \"wil3\"\n",
      "usr = r.get_redditor(un)\n",
      "thing_limit=None\n",
      "gen = usr.get_submitted(limit=thing_limit)\n",
      "karm = {}\n",
      "for thing in gen:\n",
      "    sr = thing.subreddit.display_name\n",
      "    karm[sr] = (karm.get(sr,0)+thing.score)\n",
      "#print dir(karm)\n",
      "for key in karm:\n",
      "    print key,\n",
      "    print karm[key]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \n",
      "import praw\n",
      "\n",
      "# declare a helper function with optional args\n",
      "def bleep(*args):\n",
      "    print \"done\"\n",
      "\n",
      "# can sandbox bots using /r/test\n",
      "r = praw.Reddit('Comment scraper 1.0 by /u/testbots, account associated with /u/wil3')\n",
      "r.login('testbots','ertdfgCVB')\n",
      "submission = r.get_submission(submission_id='2a12v3')\n",
      "#comment_forest = submission.comments\n",
      "flat_comments = praw.helpers.flatten_tree(submission.comments)\n",
      "#print flat_comments\n",
      "# creates an empty set data structure\n",
      "already_done = set()\n",
      "bleep()\n",
      "for comment in flat_comments:\n",
      "    # avoid throwing an exception if the comment doesn't have the queried attribute\n",
      "    try:\n",
      "        if comment.body == \"Hello\" and comment.id not in already_done:\n",
      "            print \"here\"\n",
      "            #comment.reply(' world!')\n",
      "            print \"here\"\n",
      "            already_done.add(comment.id)\n",
      "    except AttributeError:\n",
      "        pass\n",
      "        \n",
      "        \n",
      "\n",
      "        #srt_name = \"Physics\"\n",
      "        #srt = r.get_subreddit(srt)\n",
      "        #srt_coms = srt.get_comments()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "One deep Markov Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bodytext = corpus.split()\n",
      "seed_word = \"this\"\n",
      "message = seed_word # use word from thread found in corpus\n",
      "while len(message) < 1000:\n",
      "    found_indices = [i for (i, x) in enumerate(bodytext) if x == seed_word]\n",
      "    next_words = [bodytext[index + 1] for index in found_indices]\n",
      "    next_word = random.choice(next_words)\n",
      "    message = message +' '+next_word\n",
      "    seed_word = next_word\n",
      "\n",
      "print(message)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Context-free grammar text generator"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Clean and tag a corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import string\n",
      "import glob\n",
      "import random\n",
      "import cPickle as pickle\n",
      "  \n",
      "path = 'revelation/revelation.txt'   \n",
      "corpus_members=glob.glob(path)\n",
      "corpus = ''\n",
      "# get rid of random line breaks and exclude troublesome expressions like quotes\n",
      "for member in corpus_members:\n",
      "    with open (member, \"r\") as openfile:\n",
      "        data = openfile.read()\n",
      "        for badchar in ['\\t','\\n','-\\n','\\'','\\\"','`','|','--']:\n",
      "            data = data.replace(badchar, ' ')\n",
      "        data = data.replace('.','. ')\n",
      "        data = data.replace(',',', ')\n",
      "        data = data.replace(';','; ')\n",
      "        data = data.replace(':',': ')\n",
      "    corpus = corpus + ' '+ data\n",
      "tokens = nltk.word_tokenize(corpus)\n",
      "\n",
      "# looks at each word in the context of sentence and tags it\n",
      "pos_tagged_tokens = nltk.pos_tag(tokens)\n",
      "pickle.dump( pos_tagged_tokens, open( \"revelation/revelation_tagged.pkl\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Record all terminal characters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('revelation/revelation_tagged.pkl', 'rb') as handle:\n",
      "    pos_tagged_tokens = pickle.load(handle)\n",
      "\n",
      "# clear file\n",
      "open('revelation/revelation_rules.txt', 'w').close()\n",
      "\n",
      "file = open('revelation/revelation_rules.txt', 'a')\n",
      "\n",
      "# need to come up with some valid rules\n",
      "# tree = '''S -> NP VP\n",
      "# PP -> IN NP\n",
      "# NP -> DT NN | DT NN PP\n",
      "# VP -> VB NP | VP PP \\n'''\n",
      "# file.write(tree)\n",
      "\n",
      "tags = list({tupe[1] for tupe in pos_tagged_tokens})\n",
      "# dollar signs make everything go wrong\n",
      "#tags = [item.replace('$','x')for item in tags]\n",
      "badtags = ['#','$',',','-NONE-','.',':','TO','POS',\"''\"] # try to get NONE back if possible\n",
      "tags = [item for item in tags if item not in badtags]\n",
      "for tag in tags:\n",
      "#     if tag in ['#','$',',','-NONE-','.',':']:\n",
      "#         continue\n",
      "#     else:\n",
      "    allsyms = [('\\'' + tupe[0] + '\\'') for tupe in pos_tagged_tokens if tupe[1]== tag]\n",
      "    gr_rule = (tag + \" -> \")\n",
      "    gr_rule += ' | '.join(allsyms)\n",
      "    gr_rule += '\\n'\n",
      "    gr_rule = gr_rule.replace('PRP$','PRPx')\n",
      "    gr_rule = gr_rule.replace('WP$','WPx')\n",
      "    gr_rule = gr_rule.replace('-NONE-','xNONEx')\n",
      "    file.write(gr_rule)\n",
      "\n",
      "# specify these guys when creating grammar\n",
      "# still need to work with apostrophe, hypens ``\n",
      "file.write('''xperiod -> '.'\\n''')\n",
      "file.write('''xcomma -> ','\\n''')\n",
      "file.write('''xcolon -> ':'\\n''')\n",
      "file.write('''xsemicolon -> ';'\\n''')\n",
      "file.write('''openparen -> '('\\n''')\n",
      "file.write('''closeparen -> ')'\\n''')\n",
      "file.write('''xapostrophe -> \"\\'\"\\n''')\n",
      "file.write('''xquote -> \"''\"\\n''')\n",
      "\n",
      "# Save some compiling time\n",
      "file.write('''TO -> 'to'\\n''')\n",
      "\n",
      "# need to fix this\n",
      "#file.write('''POS -> \"\\'s\"\\n''')\n",
      "\n",
      "\n",
      "file.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Get Random sentence from corpus and print syntax"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk import parse_cfg, ChartParser\n",
      "from random import choice\n",
      "\n",
      "from stat_parser import Parser\n",
      "parser = Parser()\n",
      "# pick a random sentence to parse\n",
      "# leave out the period at the end of the sentence\n",
      "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "rsent = choice(tokenizer.tokenize(corpus))\n",
      "print rsent\n",
      "parsee=parser.parse(rsent)\n",
      "\n",
      "rules = \"\"\n",
      "to_replace = [',','.',':',';',\"''\",'(',')','$','+']\n",
      "replacements = ['xcomma','xperiod','xcolon','xsemicolon',\\\n",
      "                'xquote','openparen','closeparen','x','x']\n",
      " \n",
      "# possibly add: brackets, double quotes\n",
      "\n",
      "for production in parsee.productions():\n",
      "    rules += str(production) + '\\n'\n",
      "\n",
      "# now re-tag special characters\n",
      "swappairs = zip(to_replace, replacements)\n",
      "for member in swappairs:\n",
      "    rules = rules.replace(member[0],member[1])\n",
      "\n",
      "print rules\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Because you  have obeyed My call to patient endurance I will keep you  safe from the hour of trial which is to come upon the whole  world,  to test all who live upon the earth.\n",
        "PRNxSBAR -> IN S\n",
        "IN -> 'because'\n",
        "S -> NP VP xperiod\n",
        "NP -> PRP\n",
        "PRP -> 'you'\n",
        "VP -> VBP VBD SBARxS\n",
        "VBP -> 'have'\n",
        "VBD -> 'obeyed'\n",
        "SBARxS -> NP NP VP\n",
        "NP -> NP PP\n",
        "NP -> PRPx NN\n",
        "PRPx -> 'My'\n",
        "NN -> 'call'\n",
        "PP -> TO NP\n",
        "TO -> 'to'\n",
        "NP -> JJ NN\n",
        "JJ -> 'patient'\n",
        "NN -> 'endurance'\n",
        "NP -> PRP\n",
        "PRP -> 'I'\n",
        "VP -> MD VB SBARxS\n",
        "MD -> 'will'\n",
        "VB -> 'keep'\n",
        "SBARxS -> NP VP\n",
        "NP -> PRP\n",
        "PRP -> 'you'\n",
        "VP -> VB PP\n",
        "VB -> 'safe'\n",
        "PP -> IN NP\n",
        "IN -> 'from'\n",
        "NP -> NP PP\n",
        "NP -> NP PP\n",
        "NP -> DT NN\n",
        "DT -> 'the'\n",
        "NN -> 'hour'\n",
        "PP -> IN NP\n",
        "IN -> 'of'\n",
        "NP -> NN SBAR xcomma\n",
        "NN -> 'trial'\n",
        "SBAR -> WHNP SxVP\n",
        "WHNP -> WDT\n",
        "WDT -> 'which'\n",
        "SxVP -> VBZ TO VP\n",
        "VBZ -> 'is'\n",
        "TO -> 'to'\n",
        "VP -> VBN PP\n",
        "VBN -> 'come'\n",
        "PP -> IN NP\n",
        "IN -> 'upon'\n",
        "NP -> DT JJ NN\n",
        "DT -> 'the'\n",
        "JJ -> 'whole'\n",
        "NN -> 'world'\n",
        "xcomma -> 'xcomma'\n",
        "PP -> TO NP\n",
        "TO -> 'to'\n",
        "NP -> NN NP SBAR\n",
        "NN -> 'test'\n",
        "NP -> DT\n",
        "DT -> 'all'\n",
        "SBAR -> WHNP SxVP\n",
        "WHNP -> WP\n",
        "WP -> 'who'\n",
        "SxVP -> VBP PP\n",
        "VBP -> 'live'\n",
        "PP -> IN NP\n",
        "IN -> 'upon'\n",
        "NP -> DT NN\n",
        "DT -> 'the'\n",
        "NN -> 'earth'\n",
        "xperiod -> 'xperiod'\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Run grammar model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gramr = nltk.parse_cfg(\"\"\"S -> NP VP\n",
      "# ... PP -> P NP\n",
      "# ... NP -> Det N | Det N PP | 'I'\n",
      "# ... VP -> V NP | VP PP\n",
      "# ... Det -> 'an' | 'my'\n",
      "# ... N -> 'elephant' | 'pajamas'\n",
      "# ... V -> 'shot'\n",
      "# ... P -> 'in'\n",
      "# ... \"\"\")\n",
      "\n",
      "import nltk\n",
      "\n",
      "from nltk import parse_cfg, ChartParser\n",
      "from random import choice\n",
      "\n",
      "def produce(grammar, symbol):\n",
      "    words = []\n",
      "    productions = grammar.productions(lhs = symbol)\n",
      "    production = choice(productions)\n",
      "    for sym in production.rhs():\n",
      "        if isinstance(sym, str):\n",
      "            words.append(sym)\n",
      "        # recursion\n",
      "        else:\n",
      "#             print sym\n",
      "            words.extend(produce(grammar, sym))\n",
      "    return words\n",
      "\n",
      "# read nonterminal rules from treebank file\n",
      "file = open('revelation/revelation_NTrules.txt', 'r')\n",
      "cfg_str = file.read()\n",
      "file.close()\n",
      "\n",
      "# read leaves from corpus\n",
      "file = open('revelation/revelation_rules.txt', 'r')\n",
      "cfg_str += '\\n' + file.read()\n",
      "file.close()\n",
      "\n",
      "grammar = parse_cfg('''\n",
      "S -> NP',' VP\n",
      "PP -> IN NP\n",
      "NP -> DT NN | DT NN PP | 'I'\n",
      "VP -> V NP | VP PP\n",
      "V -> 'shot' | 'killed' | 'wounded'\n",
      "DT -> 'an' | 'my'\n",
      "NN -> 'elephant'\n",
      "H -> 'unused'\n",
      "IN -> 'in' | 'outside'\n",
      "''')\n",
      "\n",
      "grammar = parse_cfg(cfg_str)\n",
      "\n",
      "parser = ChartParser(grammar)\n",
      "\n",
      "gr = parser.grammar()\n",
      "\n",
      "# make an S symbol to start the fun\n",
      "tgr = ChartParser(parse_cfg('''S -> NP VP''')).grammar()\n",
      "tgr.start()\n",
      "# gr.max_len()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "S"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#message = produce(gr, tgr.start())\n",
      "for ii in xrange(10):\n",
      "    print ' '.join(produce(gr, tgr.start())) \n",
      "\n",
      "\n",
      "# # tokenize by sentence and pick some random sentences to use?\n",
      "# # really need to get punctuation working\n",
      "# from stat_parser import Parser\n",
      "# parser = Parser()\n",
      "# kk=parser.parse(\"At the end of the nineteenth century the well-tested mechanical principles of Isaac Newton were the very heart of physical theory.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "their pieces kill the sort\n",
        "the angel come up to another translucent\n",
        "and weep any stone .\n",
        "her timeless will measure them to the day\n",
        ", hold created with earth noises and hurled every nation .\n",
        "who been of you to devour to those judge and her trumpet : the reality for A trumpet , and to they in rescue , and came close on they .\n",
        "the angel through their people muster on they\n",
        "I what are could be there weep God the trumpet\n",
        "there shown out upon the voice\n",
        "it be in seventh which is to trample , I ,\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "create a grammar file from Treebank"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "from nltk.corpus import treebank\n",
      "from nltk.grammar import ContextFreeGrammar, Nonterminal\n",
      "\n",
      "tbank_productions = set(production for sent in treebank.parsed_sents()\n",
      "                        for production in sent.productions())\n",
      "tbank_grammar = ContextFreeGrammar(Nonterminal('S'), list(tbank_productions))\n",
      "\n",
      "allsyms = {thing.lhs() for thing in tbank_grammar.productions()}\n",
      "rule_list = ''\n",
      "for sym in allsyms:\n",
      "    if str(sym) not in tags:\n",
      "        if str(sym) not in badtags:\n",
      "            rules_sym = tbank_grammar.productions(lhs = sym)\n",
      "            for rule in rules_sym:\n",
      "                strule = str(rule)\n",
      "                strule = strule.replace('PRP$','PRPx')\n",
      "                strule = strule.replace('WP$','WPx')\n",
      "                strule = strule.replace('ADVP|PRT','ADVPxPRT')\n",
      "                strule = strule.replace('ADVP-PRD-LOC=3','ADVP-PRD-LOCx3')\n",
      "                strule = strule.replace('-LRB-','xLRBx')\n",
      "                strule = strule.replace('-RRB-','xRRBx')\n",
      "                strule = strule.replace('-NONE-','xNONEx') # need to update leaves as well\n",
      "                rule_list += strule + '\\n'\n",
      "    else:   \n",
      "        continue\n",
      "print rule_list\n",
      "file = open('treebank_rules.txt', 'w')\n",
      "file.write(rule_list)\n",
      "file.close()\n",
      "\n",
      "\n",
      "# need to deal with these special characters:\n",
      "#  -NONE- ``  .    -LRB- with LRB -RRB- '' :  \n",
      "# ADVP-PRD-LOC=3 ADJP-PRD1 $ #\n",
      "#  -> \n",
      "# -> '`'\n",
      "# -> \"\"\n",
      "# -> \"'\"\n",
      "# maybe try 'xCOMMAx'. Issue is that the symbol , has be be nonterminal (ie, it has to point to a terminal)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file = open('stringtest.txt', 'r')\n",
      "print file.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ",\n",
        "``\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The uniform from the energy represent the appearance because the whole\n",
      "\n",
      "the due condition source die as own orbit Parts and arises of the aether is the destiny. He system time a following arc now the a\u00bb At heart part more though a varying orbital page conclusion referred the opposite problem believes was more causally"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# problem: searching for only identifiable tags is dropping clause symbols, etc. \n",
      "# But if a terminal symbo is missing, an IndexError will be raised\n",
      "# instead just make an lhs list and check for membership?\n",
      "\n",
      "rule_list = ''\n",
      "gram_leaves = [loc.rhs() for loc in list(tbank_productions)]\n",
      "gram_heads = [loc.lhs() for loc in list(tbank_productions)]\n",
      "gram_list= list(tbank_productions)\n",
      "for thing in gram_list:\n",
      "    thing_head = thing.lhs()\n",
      "    thing_leave = thing.rhs()\n",
      "    if str(thing_head) in tags:\n",
      "        #print str(thing_head)\n",
      "        continue\n",
      "    else:\n",
      "        message = str(thing_head) + \" -> \"\n",
      "        collection = [str(thing2) for thing2 in thing_leave]\n",
      "        for item in collection:\n",
      "            message += \" | \" + str(item)\n",
      "            rule_list += '\\n'+message\n",
      "\n",
      "    \n",
      "# # Get rid of dead heads\n",
      "# new_rule_list= ''\n",
      "# for line in rule_list.splitlines():\n",
      "#     if ' -> ' not in line[-5:]:\n",
      "#         new_rule_list +=line+'\\n'\n",
      "        \n",
      "rule_list=new_rule_list\n",
      "\n",
      "#get ride of first OR\n",
      "rule_list = rule_list.replace(' ->  |', ' ->  ')\n",
      "\n",
      "print rule_list\n",
      "# file = open('treebank_rules.txt', 'w')\n",
      "# file.write(rule_list)\n",
      "# file.close()\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parser = ChartParser(tbank_grammar)\n",
      "gr = parser.grammar()\n",
      "print ' '.join(produce(gr, gr.start()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "NGram 3 markov"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "tokens = nltk.word_tokenize(corpus)\n",
      "# tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n",
      "# content_text = ' '.join(article.content for article in articles)\n",
      "# tokenized_content = tokenizer.tokenize(content_text)\n",
      "content_model = nltk.NgramModel(2, tokens)\n",
      "\n",
      "#starting_words = content_model.generate(100)[-2:]\n",
      "#content = content_model.generate(words_to_generate, starting_words)\n",
      "#print ' '.join(content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# will throw an error for small corpus\n",
      "robotext = content_model.generate(100,'This')\n",
      "print ' '.join(robotext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 86 samples> sums to 0.5179293212281115; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 1 samples> sums to 0.3582920585555367; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 12 samples> sums to 0.3010968340140925; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 186 samples> sums to 0.9390083250809893; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 236 samples> sums to 0.7362707529206318; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 148 samples> sums to 0.619494780052439; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 3 samples> sums to 0.695272637323873; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 302 samples> sums to 0.6680326406726631; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 236 samples> sums to 0.7861922674700187; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 11 samples> sums to 0.2836050264010106; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 1635 samples> sums to 0.8187765735998777; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 3908 samples> sums to 0.8755396659910119; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 2 samples> sums to 0.6897185014632843; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 1345 samples> sums to 0.9468891488797238; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 5 samples> sums to 0.39148998461477236; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 1 samples> sums to 0.3272033699870952; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 20 samples> sums to 0.6387292965574733; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 11 samples> sums to 0.6250427862031722; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 546 samples> sums to 0.9390917095506107; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 4 samples> sums to 0.846753884807785; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 2 samples> sums to 0.44289185405690257; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 751 samples> sums to 0.902137284237809; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 17 samples> sums to 0.4981912022997689; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 30 samples> sums to 0.3329690568308621; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 970 samples> sums to 0.9859847773245114; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 30 samples> sums to 0.6587215162030653; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 14 samples> sums to 0.8799099873029482; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 22 samples> sums to 0.6974415833323815; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 2637 samples> sums to 0.968223958757137; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 14 samples> sums to 0.6891132524585208; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 1079 samples> sums to 0.9977962542610109; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 57 samples> sums to 0.6687850903227524; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 2637 samples> sums to 0.8163330636287127; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 173 samples> sums to 0.7971880767304437; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 20 samples> sums to 0.6553918642529108; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 176 samples> sums to 0.41453570050350164; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 3 samples> sums to 0.605219877384972; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 6 samples> sums to 0.8289757430184085; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 18 samples> sums to 0.8253977048198456; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "T h i s apprehensions as he had hitherto been present to your health rendered , no disaster is murdered , on your duty towards the most beautiful that you could I opened my , I , the reflections determined thenceforth to a direction , and my appetite. One by Elizabeth. She was not unfolded to recollect what has been adduced against me was free last night ; such a fiend can not describe their native town of great crime , in death shall be the beginning of food or take their inquiries clear conception of the dashing waves continually renewed violence except at\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 6 samples> sums to 0.1866970521909247; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n",
        "/Library/Python/2.7/site-packages/nltk/probability.py:598: UserWarning: Probability distribution <SimpleGoodTuringProbDist based on 11 samples> sums to 0.5961183808511158; generate() is returning an arbitrary sample.\n",
        "  \" is returning an arbitrary sample.\" % (self, 1-p))\n"
       ]
      }
     ],
     "prompt_number": 201
    }
   ],
   "metadata": {}
  }
 ]
}